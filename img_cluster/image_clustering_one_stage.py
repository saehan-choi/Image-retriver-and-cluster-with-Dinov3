import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
import numpy as np
import albumentations as A
import shutil
import hdbscan

from albumentations.pytorch import ToTensorV2
from tqdm import tqdm


# =====================================================================
# âš™ï¸ ì„¤ì •
# =====================================================================
class CFG:
    device = "cuda" if torch.cuda.is_available() else "cpu"

    dinov3_location = "C:/dinov3/"
    model_name = "dinov3_vits16"
    dinov3_weights_path = "C:/dinov3/dinov3_vits16_pretrain_lvd1689m-08c60483.pth"

    img_resize = (800, 800)

    # â­ NG ì´ë¯¸ì§€ í´ë” ì „ì²´ í´ëŸ¬ìŠ¤í„°ë§
    target_folder = r"C:\4-2CAL_welder\dataset\Backup_í˜„ì¥\okng_datasets\NG\NG_images"

    batch_size = 64

    # ì¶œë ¥ ìœ„ì¹˜
    cluster_output = r"C:\4-2CAL_welder\dataset\Backup_í˜„ì¥\okng_datasets\NG\NG_cluseters"


# =====================================================================
# ğŸ§  DINOv3 ì„ë² ë”© ëª¨ë¸
# =====================================================================
class DinoEmbedder(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.hub.load(
            repo_or_dir=CFG.dinov3_location,
            model=CFG.model_name,
            source="local",
            weights=CFG.dinov3_weights_path,
        )

    def forward(self, x):
        with torch.no_grad():
            out = self.model.forward_features(x)
            if isinstance(out, dict):
                x = out.get("x_norm_clstoken", list(out.values())[0])
            else:
                x = out
        return x


# =====================================================================
# ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜
# =====================================================================
def imread(path):
    data = np.fromfile(path, dtype=np.uint8)
    return cv2.imdecode(data, cv2.IMREAD_COLOR)


# Albumentations transform
transform = A.Compose([
    A.Resize(*CFG.img_resize),
    A.Normalize(),
    ToTensorV2(),
])


# =====================================================================
# ë°°ì¹˜ ë‹¨ìœ„ ì„ë² ë”©
# =====================================================================
def get_embeddings_batch(model, paths, batch_size=32):
    embeddings = []
    batch_tensors = []

    for p in tqdm(paths, desc="Embedding"):
        img = imread(p)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        tensor = transform(image=img)["image"]
        batch_tensors.append(tensor)

        # ë°°ì¹˜ ì²˜ë¦¬
        if len(batch_tensors) == batch_size:
            batch = torch.stack(batch_tensors).to(CFG.device)
            with torch.no_grad():
                z = model(batch)
                z = F.normalize(z, dim=1)
            embeddings.append(z.cpu())
            batch_tensors = []

    # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
    if len(batch_tensors) > 0:
        batch = torch.stack(batch_tensors).to(CFG.device)
        with torch.no_grad():
            z = model(batch)
            z = F.normalize(z, dim=1)
        embeddings.append(z.cpu())

    return torch.cat(embeddings, dim=0)


# =====================================================================
# í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
# =====================================================================
def load_images(folder):
    exts = (".png", ".jpg", ".jpeg", ".bmp")
    return sorted([
        os.path.join(folder, f)
        for f in os.listdir(folder)
        if f.lower().endswith(exts)
    ])


# =====================================================================
# í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
# =====================================================================
def cluster_ng_images():
    # ì´ë¯¸ì§€ ê²½ë¡œë“¤
    img_paths = load_images(CFG.target_folder)
    print(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(img_paths)}")

    if len(img_paths) == 0:
        print("âš  ì´ë¯¸ì§€ ì—†ìŒ")
        return

    # ëª¨ë¸ ë¡œë“œ
    print("\nâ­ DINOv3 ë¡œë”© ì¤‘...")
    model = DinoEmbedder().to(CFG.device)
    model.eval()

    # ì„ë² ë”© ì¶”ì¶œ
    print("\nâ­ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
    embs = get_embeddings_batch(model, img_paths, batch_size=CFG.batch_size)
    embs_np = embs.numpy()

    # í´ëŸ¬ìŠ¤í„°ë§
    print("\nâ­ HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=10,
        min_samples=3
    )
    labels = clusterer.fit_predict(embs_np)

    # ì¶œë ¥ í´ë” ìƒì„±
    os.makedirs(CFG.cluster_output, exist_ok=True)

    print("\nğŸ“¦ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì •ë¦¬ ì¤‘...")

    for idx, label in enumerate(labels):
        cluster_dir = os.path.join(CFG.cluster_output, f"cluster_{label}")
        os.makedirs(cluster_dir, exist_ok=True)

        src = img_paths[idx]
        dst = os.path.join(cluster_dir, os.path.basename(src))
        shutil.copy(src, dst)

    print("\nğŸ‰ ì™„ë£Œ! í´ëŸ¬ìŠ¤í„°ë§ëœ í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")


# =====================================================================
# ì‹¤í–‰
# =====================================================================
if __name__ == "__main__":
    cluster_ng_images()
