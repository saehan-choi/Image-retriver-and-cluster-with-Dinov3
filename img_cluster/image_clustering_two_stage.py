import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
import numpy as np
import albumentations as A
import shutil
import hdbscan

from albumentations.pytorch import ToTensorV2
from tqdm import tqdm


# =====================================================================
# âš™ï¸ ì„¤ì •
# =====================================================================
class CFG:
    device = "cuda" if torch.cuda.is_available() else "cpu"

    dinov3_location = "C:/dinov3/"
    model_name = "dinov3_vits16"
    dinov3_weights_path = "C:/dinov3/dinov3_vits16_pretrain_lvd1689m-08c60483.pth"

    img_resize = (800, 800)

    target_folder = r"C:\4-2CAL_welder\dataset\Backup_í˜„ì¥\okng_datasets\NG\NG_images"
    batch_size = 64

    cluster_output = r"C:\4-2CAL_welder\dataset\Backup_í˜„ì¥\okng_datasets\NG\NG_cluseters"

    # 1ì°¨ & 2ì°¨ íŒŒë¼ë¯¸í„° ë¶„ë¦¬
    min_cluster_size_1 = 10
    min_samples_1 = 3

    min_cluster_size_2 = 5
    min_samples_2 = 2

    # ëª‡ ì¥ ì´ìƒì´ë©´ 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰í• ì§€ (ì„ê³„ê°’)
    second_pass_threshold = 50


# =====================================================================
# ğŸ§  DINOv3 ì„ë² ë”© ëª¨ë¸
# =====================================================================
class DinoEmbedder(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = torch.hub.load(
            repo_or_dir=CFG.dinov3_location,
            model=CFG.model_name,
            source="local",
            weights=CFG.dinov3_weights_path,
        )

    def forward(self, x):
        with torch.no_grad():
            out = self.model.forward_features(x)
            if isinstance(out, dict):
                x = out.get("x_norm_gettoken", list(out.values())[0])
            else:
                x = out
        return x


# =====================================================================
# ì´ë¯¸ì§€ ë¡œë”© í•¨ìˆ˜
# =====================================================================
def imread(path):
    data = np.fromfile(path, dtype=np.uint8)
    return cv2.imdecode(data, cv2.IMREAD_COLOR)


# Albumentations transform
transform = A.Compose([
    A.Resize(*CFG.img_resize),
    A.Normalize(),
    ToTensorV2(),
])


# =====================================================================
# ë°°ì¹˜ ë‹¨ìœ„ ì„ë² ë”©
# =====================================================================
def get_embeddings_batch(model, paths, batch_size=32):
    embeddings = []
    batch_tensors = []

    for p in tqdm(paths, desc="Embedding"):
        img = imread(p)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        tensor = transform(image=img)["image"]
        batch_tensors.append(tensor)

        if len(batch_tensors) == batch_size:
            batch = torch.stack(batch_tensors).to(CFG.device)
            with torch.no_grad():
                z = model(batch)
                z = F.normalize(z, dim=1)
            embeddings.append(z.cpu())
            batch_tensors = []

    if len(batch_tensors) > 0:
        batch = torch.stack(batch_tensors).to(CFG.device)
        with torch.no_grad():
            z = model(batch)
            z = F.normalize(z, dim=1)
        embeddings.append(z.cpu())

    return torch.cat(embeddings, dim=0)


# =====================================================================
# í´ë”ì—ì„œ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
# =====================================================================
def load_images(folder):
    exts = (".png", ".jpg", ".jpeg", ".bmp")
    return sorted([
        os.path.join(folder, f)
        for f in os.listdir(folder)
        if f.lower().endswith(exts)
    ])


# =====================================================================
# HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ í•¨ìˆ˜
# =====================================================================
def run_hdbscan(embs_np, min_cluster_size, min_samples):
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=min_cluster_size,
        min_samples=min_samples,
        metric="euclidean"
    )
    return clusterer.fit_predict(embs_np)


# =====================================================================
# 2ë‹¨ê³„ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
# =====================================================================
def second_pass_cluster(cluster_path):
    print(f"\nğŸ”¥ 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰: {cluster_path}")

    img_paths = load_images(cluster_path)
    if len(img_paths) < CFG.min_cluster_size_2:
        print("2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤í‚µ (ì´ë¯¸ì§€ ë„ˆë¬´ ì ìŒ)")
        return

    # ëª¨ë¸ ë¡œë“œ
    model = DinoEmbedder().to(CFG.device)
    model.eval()

    # ì„ë² ë”© ê³„ì‚°
    embs = get_embeddings_batch(model, img_paths, batch_size=CFG.batch_size)
    labels = run_hdbscan(
        embs.numpy(),
        CFG.min_cluster_size_2,
        CFG.min_samples_2
    )

    # ê²°ê³¼ ì €ì¥
    for idx, label in enumerate(labels):
        subfolder = os.path.join(cluster_path, f"subcluster_{label}")
        os.makedirs(subfolder, exist_ok=True)

        src = img_paths[idx]
        dst = os.path.join(subfolder, os.path.basename(src))
        shutil.copy(src, dst)

    print("2ì°¨ ì™„ë£Œ!")


# =====================================================================
# 1ë‹¨ê³„ + 2ë‹¨ê³„ ì „ì²´ íŒŒì´í”„ë¼ì¸
# =====================================================================
def cluster_ng_images():
    img_paths = load_images(CFG.target_folder)
    print(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(img_paths)}")

    if len(img_paths) == 0:
        print("âš  ì´ë¯¸ì§€ ì—†ìŒ")
        return

    print("\nâ­ 1ì°¨ ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = DinoEmbedder().to(CFG.device)
    model.eval()

    print("\nâ­ 1ì°¨ ì„ë² ë”© ì¶”ì¶œ ì¤‘...")
    embs = get_embeddings_batch(model, img_paths, batch_size=CFG.batch_size)
    labels = run_hdbscan(
        embs.numpy(),
        CFG.min_cluster_size_1,
        CFG.min_samples_1
    )

    # 1ì°¨ ê²°ê³¼ ì €ì¥
    os.makedirs(CFG.cluster_output, exist_ok=True)

    cluster_members = {}  # {cluster_id: [img_paths]}

    for idx, label in enumerate(labels):
        cluster_members.setdefault(label, []).append(img_paths[idx])

    print("\nğŸ“¦ 1ì°¨ í´ëŸ¬ìŠ¤í„° ì €ì¥")

    # 1ì°¨ ê²°ê³¼ ì €ì¥
    for label, paths in cluster_members.items():
        cluster_dir = os.path.join(CFG.cluster_output, f"cluster_{label}")
        os.makedirs(cluster_dir, exist_ok=True)
        for p in paths:
            shutil.copy(p, os.path.join(cluster_dir, os.path.basename(p)))

        # 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ëŒ€ìƒì¸ì§€ í™•ì¸
        if len(paths) >= CFG.second_pass_threshold and label != -1:
            second_pass_cluster(cluster_dir)

    print("\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")


# =====================================================================
# ì‹¤í–‰
# =====================================================================
if __name__ == "__main__":
    cluster_ng_images()
